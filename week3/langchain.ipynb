{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://github.com/samwit/langchain-tutorials\n",
    "\n",
    "Before running, create a new virtual environment\n",
    "\n",
    "```\n",
    "py -m venv .venv\n",
    "```\n",
    "\n",
    "Then activate it\n",
    "\n",
    "In Bash:\n",
    "```\n",
    "source .venv/bin/activate\n",
    "```\n",
    "\n",
    "CMD:\n",
    "```\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "LangChain is a framework available in Python and Node. It provides a lot of tools useful for building simple (and somewhat advanced) applications. Access to several models, conversation templates and tools. It uses \"chains\" which combine LLMs, formatted prompts, memory and tools to create useful applications.\n",
    "\n",
    "Here, we will cover 2 core topics:\n",
    "- Conversations with Memory\n",
    "- Tools\n",
    "\n",
    "After this, you should have the skills necessary to build a simple application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    model_name = 'gpt-3.5-turbo-0125',\n",
    "    temperature = 0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Hi! My name is {name}\"\n",
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"What is my name?\"\n",
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"What was my last message?\"\n",
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory = ConversationSummaryMemory(llm=ChatOpenAI())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hello! Im Artur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What was my last message?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Here are 3 facts about me. I was a student at SFU, I am a software developer, and I like fishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation.memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other approaches\n",
    "\n",
    "- ConversationBufferWindowMemory: keep last `n` messages, discard the rest\n",
    "- ConversationSummaryBufferMemory: keep last `n` messages, summarize the rest\n",
    "- ConversationKGMemory: knowledge graph\n",
    "- ConversationEntityMemory: extracts key information from the conversation\n",
    "\n",
    "## Why use different types of memory?\n",
    "- Save space - keeping all messages can quickly fill up the context window\n",
    "- Better accuracy - Summarizing or extracting entities can keep the prompts small while retaining all key details\n",
    "\n",
    "\n",
    "### Tools\n",
    "\n",
    "Tools are a key component of building non-trivial generative AI applications. The models are inherently limited in the information they have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple example is asking the model something about the present day.\n",
    "summary_memory = ConversationSummaryMemory(llm=ChatOpenAI())\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n",
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conversation.predict(input=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though it claims to check the price, it cannot actually do it. We need to give it that ability explicitly\n",
    "# Lets give it some tools\n",
    "\n",
    "from langchain.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.utilities import PythonREPL\n",
    "from langchain.agents import Tool\n",
    "\n",
    "wikipedia = WikipediaAPIWrapper()\n",
    "search = DuckDuckGoSearchRun()\n",
    "py_repl = PythonREPL()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page: JavaScript\\nSummary: JavaScript (), often abbreviated as JS, is a programming language and core technology of the World Wide Web, alongside HTML and CSS. As of 2024, 98.9% of websites use JavaScript on the client side for webpage behavior, often incorporating third-party libraries. All major web browsers have a dedicated JavaScript engine to execute the code on users' devices.\\nJavaScript is a high-level, often just-in-time compiled language that conforms to the ECMAScript standard. It has dynamic typing, prototype-based object-orientation, and first-class functions. It is multi-paradigm, supporting event-driven, functional, and imperative programming styles. It has application programming interfaces (APIs) for working with text, dates, regular expressions, standard data structures, and the Document Object Model (DOM).\\nThe ECMAScript standard does not include any input/output (I/O), such as networking, storage, or graphics facilities. In practice, the web browser or other runtime system provides JavaScript APIs for I/O.\\nJavaScript engines were originally used only in web browsers, but are now core components of some servers and a variety of applications. The most popular runtime system for this usage is Node.js.\\nAlthough Java and JavaScript are similar in name, syntax, and respective standard libraries, the two languages are distinct and differ greatly in design.\\n\\nPage: JavaScript engine\\nSummary: A JavaScript engine is a software component that executes JavaScript code. The first JavaScript engines were mere interpreters, but all relevant modern engines use just-in-time compilation for improved performance.JavaScript engines are typically developed by web browser vendors, and every major browser has one. In a browser, the JavaScript engine runs in concert with the rendering engine via the Document Object Model.\\nThe use of JavaScript engines is not limited to browsers. For example, the V8 engine is a core component of the Node.js and Deno runtime systems.\\nSince ECMAScript is the standardized specification of JavaScript, ECMAScript engine is another name for these engines. With the advent of WebAssembly, some engines can also execute this code in the same sandbox as regular JavaScript code.\\n\\nPage: JavaScript library\\nSummary: A JavaScript library is a library of pre-written JavaScript code that allows for easier development of JavaScript-based applications, especially for AJAX and other web-centric technologies. They can be included in a website by embedding it directly in the HTML via a script tag.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.run(\"JavaScript\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.run(\"Tesla stock price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_repl.run(\"def add(a, b):\\n    return a + b\\n\\nprint(add(1, 2))\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"wikipedia\",\n",
    "        func=wikipedia.run,\n",
    "        description=\"Useful when you need to find information about a topic, country or person on wikipedia\"\n",
    "    ),\n",
    "        Tool(\n",
    "        name=\"duckduckgo\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for when you need to do a search on the internet to find information that another tool can't find.\"\n",
    "    ),\n",
    "        Tool(\n",
    "        name=\"python repl\",\n",
    "        func=py_repl.run,\n",
    "        description=\"Useful for when you need to use python to answer a question. You should input python code\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tool(name='wikipedia', description='Useful when you need to find information about a topic, country or person on wikipedia', func=<bound method WikipediaAPIWrapper.run of WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\artur\\\\OneDrive - sfu.ca\\\\Desktop\\\\Programming\\\\genai-tutorials\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000)>), Tool(name='duckduckgo', description=\"Useful for when you need to do a search on the internet to find information that another tool can't find.\", func=<bound method BaseTool.run of DuckDuckGoSearchRun()>), Tool(name='python repl', description='Useful for when you need to use python to answer a question. You should input python code', func=<bound method PythonREPL.run of PythonREPL(globals={}, locals={})>)]\n"
     ]
    }
   ],
   "source": [
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "zero_shot_agent.run(\"What is 9 + 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent.run(\"is 11 a prime number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does the prompt look like\n",
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent.run(\"What is 2 * the price of tesla stock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "\n",
    "Explore the [Complete list of langchain tools](https://python.langchain.com/docs/integrations/tools/).\n",
    "\n",
    "Try [custom prompts](https://python.langchain.com/docs/modules/model_io/prompts/)\n",
    "\n",
    "Build more complex [agents](https://python.langchain.com/docs/modules/agents/)\n",
    "\n",
    "## Apply what you learned!!\n",
    "\n",
    "# Hackathon next week\n",
    "\n",
    "- In small groups\n",
    "- Think of a problem you face that can be solved by generative AI\n",
    "- Build an app to solve it\n",
    "    - Use any model but gpt-3.5 is probably the best starting point\n",
    "    - Play around with prompting\n",
    "    - Use at least one external tool (see list above) to enhance the functionality\n",
    "    - UI doesnt matter but if you have time make it look nice (running in terminal is fine)\n",
    "    - Don't have to use LangChain if you want to do it from scratch, but this will take longer\n",
    "    - If you're not comfortable with Python, LangChain is also available for [JavaScript/TypeScript](https://js.langchain.com/docs/get_started). Alternatively, use any language you want with 3rd party libraries or directly calling an LLM API.\n",
    "    - Winner gets a prize!\n",
    "\n",
    "We will have demos during the Friday session and choose the best app.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
